@article{busso2008iemocap,
  title={IEMOCAP: Interactive emotional dyadic motion capture database},
  author={Busso, Carlos and Bulut, Murtaza and Lee, Chi-Chun and Kazemzadeh, Abe and Mower, Emily and Kim, Samuel and Chang, Jeannette N and Lee, Sungbok and Narayanan, Shrikanth S},
  journal={Language resources and evaluation},
  volume={42},
  number={4},
  pages={335},
  year={2008},
  publisher={Springer}
}


@inproceedings{burkhardt2005database,
  title={A database of German emotional speech},
  author={Burkhardt, Felix and Paeschke, Astrid and Rolfes, Miriam and Sendlmeier, Walter F and Weiss, Benjamin},
  booktitle={Ninth European Conference on Speech Communication and Technology},
  year={2005}
}


@article{liberman2002emotional,
  title={Emotional prosody speech and transcripts},
  author={Liberman, Mark},
  journal={http://www. ldc. upenn. edu/Catalog/CatalogEntry. jsp? catalogId= LDC2002S28},
  year={2002}
}

@article{sondhi1968new,
  title={New methods of pitch extraction},
  author={Sondhi, Mohan},
  journal={IEEE Transactions on audio and electroacoustics},
  volume={16},
  number={2},
  pages={262--266},
  year={1968},
  publisher={IEEE}
}

@incollection{teager1990evidence,
  title={Evidence for nonlinear sound production mechanisms in the vocal tract},
  author={Teager, HM and Teager, SM},
  booktitle={Speech production and speech modelling},
  pages={241--261},
  year={1990},
  publisher={Springer}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}


@article{ververidis2006emotional,
  title={Emotional speech recognition: Resources, features, and methods},
  author={Ververidis, Dimitrios and Kotropoulos, Constantine},
  journal={Speech communication},
  volume={48},
  number={9},
  pages={1162--1181},
  year={2006},
  publisher={Elsevier}
}

@article{zhou2001nonlinear,
  title={Nonlinear feature based classification of speech under stress},
  author={Zhou, Guojun and Hansen, John HL and Kaiser, James F},
  journal={IEEE Transactions on speech and audio processing},
  volume={9},
  number={3},
  pages={201--216},
  year={2001},
  publisher={IEEE}
}

@article{speechenergy,
  title={Energy (signal processing)},
  journal={Wikipedia},
  publisher={Wikipedia}
}


@article{radford2017learning,
  title={Learning to generate reviews and discovering sentiment},
  author={Radford, Alec and Jozefowicz, Rafal and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1704.01444},
  year={2017}
}

@article{jackson2014surrey,
  title={Surrey audio-visual expressed emotion (savee) database},
  author={Jackson, P and Haq, S},
  journal={University of Surrey: Guildford, UK},
  year={2014}
}

@article{fitzgerald2010harmonic,
  title={Harmonic/percussive separation using median filtering},
  author={Fitzgerald, Derry},
  year={2010},
  publisher={Dublin Institute of Technology}
}


@inproceedings{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  booktitle={Advances in neural information processing systems},
  pages={3104--3112},
  year={2014}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@article{liu2018efficient,
  title={Efficient low-rank multimodal fusion with modality-specific factors},
  author={Liu, Zhun and Shen, Ying and Lakshminarasimhan, Varun Bharadhwaj and Liang, Paul Pu and Zadeh, Amir and Morency, Louis-Philippe},
  journal={arXiv preprint arXiv:1806.00064},
  year={2018}
}
