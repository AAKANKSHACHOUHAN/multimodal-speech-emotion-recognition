{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Audio Vectors\n",
    "Now that the labels have been extracted, we'll use the compiled csv (df_iemocap.csv) to split the original wav files into multiple frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try for one file first\n",
    "import librosa\n",
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "ms.use('seaborn-muted')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/IEMOCAP_full_release/Session1/dialog/wav/Ses01F_impro01.wav'\n",
    "\n",
    "y, sr = librosa.load(file_path, sr=44100)\n",
    "y, sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "labels_df = pd.read_csv('data/pre-processed/df_iemocap.csv')\n",
    "iemocap_dir = 'data/IEMOCAP_full_release/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_vectors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 44100\n",
    "for sess in range(1, 6):\n",
    "    wav_file_path = '{}Session{}/dialog/wav/'.format(iemocap_dir, sess)\n",
    "    orig_wav_files = os.listdir(wav_file_path)\n",
    "    for orig_wav_file in orig_wav_files:\n",
    "        orig_wav_vector, _sr = librosa.load(wav_file_path + orig_wav_file, sr=sr)\n",
    "        orig_wav_file, file_format = orig_wav_file.split('.')\n",
    "        for index, row in tqdm(labels_df[labels_df['wav_file'].str.contains(orig_wav_file)].iterrows()):\n",
    "            start_time, end_time, truncated_wav_file_name, emotion, val, act, dom = row['start_time'], row['end_time'], row['wav_file'], row['emotion'], row['val'], row['act'], row['dom']\n",
    "            start_frame = math.floor(start_time * sr)\n",
    "            end_frame = math.floor(end_time * sr)\n",
    "            truncated_wav_vector = orig_wav_vector[start_frame:end_frame + 1]\n",
    "            audio_vectors[truncated_wav_file_name] = truncated_wav_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/pre-processed/audio_vectors.pkl', 'wb') as f:\n",
    "    pickle.dump(audio_vectors, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
