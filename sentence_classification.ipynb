{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_file</th>\n",
       "      <th>label</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ses04M_script03_1_F001</td>\n",
       "      <td>3</td>\n",
       "      <td>nobody knows we re here except freda and she w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ses03F_impro04_F011</td>\n",
       "      <td>4</td>\n",
       "      <td>really ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ses01M_script03_1_M003</td>\n",
       "      <td>3</td>\n",
       "      <td>we re okay right darling ? whatever happens we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ses04F_impro01_M001</td>\n",
       "      <td>2</td>\n",
       "      <td>you need a new license is that what you re tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ses04F_script02_1_M028</td>\n",
       "      <td>4</td>\n",
       "      <td>for real ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 wav_file  label  \\\n",
       "0  Ses04M_script03_1_F001      3   \n",
       "1     Ses03F_impro04_F011      4   \n",
       "2  Ses01M_script03_1_M003      3   \n",
       "3     Ses04F_impro01_M001      2   \n",
       "4  Ses04F_script02_1_M028      4   \n",
       "\n",
       "                                       transcription  \n",
       "0  nobody knows we re here except freda and she w...  \n",
       "1                                           really ?  \n",
       "2  we re okay right darling ? whatever happens we...  \n",
       "3  you need a new license is that what you re tel...  \n",
       "4                                         for real ?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_file</th>\n",
       "      <th>label</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ses05F_impro07_F033</td>\n",
       "      <td>1</td>\n",
       "      <td>laughter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ses05F_impro04_M008</td>\n",
       "      <td>5</td>\n",
       "      <td>and no i understand but you ve got to start so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ses01F_impro05_M011</td>\n",
       "      <td>5</td>\n",
       "      <td>we ve mistakenly lost your baggage . we re ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ses02F_impro03_M002</td>\n",
       "      <td>4</td>\n",
       "      <td>no . let me see .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ses01M_impro03_F003</td>\n",
       "      <td>1</td>\n",
       "      <td>is she on the run ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              wav_file  label  \\\n",
       "0  Ses05F_impro07_F033      1   \n",
       "1  Ses05F_impro04_M008      5   \n",
       "2  Ses01F_impro05_M011      5   \n",
       "3  Ses02F_impro03_M002      4   \n",
       "4  Ses01M_impro03_F003      1   \n",
       "\n",
       "                                       transcription  \n",
       "0                                          laughter   \n",
       "1  and no i understand but you ve got to start so...  \n",
       "2  we ve mistakenly lost your baggage . we re ver...  \n",
       "3                                  no . let me see .  \n",
       "4                                is she on the run ?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/t2e/text_train.csv')\n",
    "df_test = pd.read_csv('data/t2e/text_test.csv')\n",
    "display(df.head(), df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['label', 'transcription']\n",
    "df = df[col]\n",
    "df_test = df_test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'transcription'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['label', 'transcription']\n",
    "df_test.columns = ['label', 'transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "category_to_id = {'ang': 0,\n",
    "                'hap': 1,\n",
    "                'sad': 2,\n",
    "                'fea': 3,\n",
    "                'sur': 4,\n",
    "                'neu': 5}\n",
    "id_to_category = {0: 'ang', 1: 'hap', 2: 'sad', 3: 'fea', 4: 'sur', 5: 'neu'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "df.groupby('label').transcription.count().plot.bar(ylim=0)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "df_test.groupby('label').transcription.count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7837, 1927) (1960, 423)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "tfidf_test = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "\n",
    "features = tfidf.fit_transform(df.transcription).toarray()\n",
    "features_test = tfidf_test.fit_transform(df_test.transcription).toarray()\n",
    "labels = df.label\n",
    "print(features.shape, features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'ang':\n",
      "  . Most correlated unigrams:\n",
      "       . hate\n",
      "       . turn\n",
      "  . Most correlated bigrams:\n",
      "       . let kiss\n",
      "       . look shaking\n",
      "# 'fea':\n",
      "  . Most correlated unigrams:\n",
      "       . freda\n",
      "       . wonder\n",
      "  . Most correlated bigrams:\n",
      "       . wouldn ring\n",
      "       . good god\n",
      "# 'hap':\n",
      "  . Most correlated unigrams:\n",
      "       . awesome\n",
      "       . laughter\n",
      "  . Most correlated bigrams:\n",
      "       . guess came\n",
      "       . oh man\n",
      "# 'neu':\n",
      "  . Most correlated unigrams:\n",
      "       . okay\n",
      "       . um\n",
      "  . Most correlated bigrams:\n",
      "       . okay um\n",
      "       . ask marry\n",
      "# 'sad':\n",
      "  . Most correlated unigrams:\n",
      "       . wonder\n",
      "       . just\n",
      "  . Most correlated bigrams:\n",
      "       . don know\n",
      "       . good god\n",
      "# 'sur':\n",
      "  . Most correlated unigrams:\n",
      "       . bed\n",
      "       . real\n",
      "  . Most correlated bigrams:\n",
      "       . pregnant talking\n",
      "       . oh really\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "\n",
    "N = 2\n",
    "for emotion, category_id in sorted(category_to_id.items()):\n",
    "    features_chi2 = chi2(features, labels == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    \n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}':\".format(emotion))\n",
    "    print(\"  . Most correlated unigrams:\\n       . {}\".format('\\n       . '.join(unigrams[-N:])))\n",
    "    print(\"  . Most correlated bigrams:\\n       . {}\".format('\\n       . '.join(bigrams[-N:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "X_train, y_train = df['transcription'], df['label']\n",
    "X_test, y_test = df_test['transcription'], df_test['label']\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df['Consumer_complaint_narrative'], df['Product'], random_state=0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(count_vect.transform([\"This company refuses to provide me verification and validation of debt per my right under the FDCPA. I do not believe this debt is mine.\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(count_vect.transform([\"I am disputing the inaccurate information the Chex-Systems has on my credit report. I initially submitted a police report on XXXX/XXXX/16 and Chex Systems only deleted the items that I mentioned in the letter and not all the items that were actually listed on the police report. In other words they wanted me to say word for word to them what items were fraudulent. The total disregard of the police report and what accounts that it states that are fraudulent. If they just had paid a little closer attention to the police report I would not been in this position now and they would n't have to research once again. I would like the reported information to be removed : XXXX XXXX XXXX\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=1200, min_samples_split=25),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    xgb.XGBClassifier(max_depth=7, learning_rate=0.008, objective='multi:softprob', \n",
    "                      n_estimators=1200, sub_sample=0.8, num_class=len(category_to_id),\n",
    "                      booster='gbtree', n_jobs=4),\n",
    "    MLPClassifier(hidden_layer_sizes=(650, ), activation='relu', solver='adam', alpha=0.0001,\n",
    "                  batch_size='auto', learning_rate='adaptive', learning_rate_init=0.01,\n",
    "                  power_t=0.5, max_iter=1000, shuffle=True, random_state=None, tol=0.0001,\n",
    "                  verbose=False, warm_start=True, momentum=0.8, nesterovs_momentum=True,\n",
    "                  early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999,\n",
    "                  epsilon=1e-08),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000),\n",
    "]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.groupby('model_name').accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = LinearSVC()\n",
    "\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, labels, df.index, test_size=0.33, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "emotion_table = [['ang', 0], ['hap', 1], ['sad', 2], ['fea', 3], ['sur', 4], ['neu', 5]]\n",
    "category_id_df = pd.DataFrame(emotion_table, columns=['emotion', 'label'])\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=category_id_df.emotion.values, yticklabels=category_id_df.emotion.values)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from IPython.display import display\n",
    "\n",
    "# for predicted in category_id_df.label:\n",
    "#     for actual in category_id_df.label:\n",
    "#         if predicted != actual and conf_mat[actual, predicted] >= 6:\n",
    "#             print(\"'{}' predicted as '{}' : {} examples.\".format(id_to_category[actual], id_to_category[predicted], conf_mat[actual, predicted]))\n",
    "#             display(df.loc[indices_test[(y_test == actual) & (y_pred == predicted)]][['label', 'transcription']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "N = 2\n",
    "for emotion, category_id in sorted(category_to_id.items()):\n",
    "    indices = np.argsort(model.coef_[category_id])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 1][:N]\n",
    "    bigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 2][:N]\n",
    "    print(\"# '{}':\".format(emotion))\n",
    "    print(\"  . Top unigrams:\\n       . {}\".format('\\n       . '.join(unigrams)))\n",
    "    print(\"  . Top bigrams:\\n       . {}\".format('\\n       . '.join(bigrams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"Are you crazy!\",\n",
    "         \"I am not going to die right?\",\n",
    "         \"This is fantastic!\",\n",
    "         \"Okay\",\n",
    "         \"That's sad\",\n",
    "         \"Oh, really?\"]\n",
    "text_features = tfidf.transform(texts)\n",
    "predictions = model.predict(text_features)\n",
    "for text, predicted in zip(texts, predictions):\n",
    "  print('\"{}\"'.format(text))\n",
    "  print(\"  - Predicted as: '{}'\".format(id_to_category[predicted]))\n",
    "  print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
